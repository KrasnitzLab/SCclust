---
title: "SCclust T10 Tutorial"
author: "Alex Krasnitz, Jude Kendall, Junyan Song, Lubomir Chorbadjiev"
date: "`r Sys.Date()`"
output:
  pdf_document:
    number_sections: yes
    toc: yes
  html_document:
    df_print: paged
    toc: yes
header-includes:
- \usepackage[colorinlistoftodos]{todonotes}
- \hypersetup{colorlinks=true,linkcolor=blue!30!black}
- \geometry{rmargin=1.5in}
vignette: |
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# Introduction

The *SCclust* package performs phylogenetic analysis for sets of integer-valued genomic DNA copy-number profiles, each representing
a single nucleus.
For this purpose,*SCclust* determines a joint set of change points present in the profiles and uses these as features.
An incidence table is then set up, with profiles as columns and features as rows and the binary values indicating, for each profile
and feature, the presence of the feature in the profile. Dissimilarities among the profiles are computed as Fisher test p-values 
for pairs of columns. For these, false discovery rates (FDR) are computed using permutations within the table. A hierarchical tree is derived from the dissimilarity matrix, and its branches are identified as clones or sub-clones depending on the maximal dissimilarity and on the number of features shared withing the branch. 

In this tutorial we show how to use *SCclust* package using data, prepared by
*sgains* pipeline as described in 
[Example usage of sGAINS pipeline](https://github.com/KrasnitzLab/sgains/blob/master/docs/tutorial-navin2011.md). 
*SCclust* package is called as the last step in processing data from *sgains* pipeline. In this tutoral
we show how *SCclust* package could be used independently from *sgains* pipeline.

We assume that you have an R environment and have installed *SCclust* package as described in the `README.md`.

# Data

## Data for the T10 case

This tutorial is based on data published in:
[Navin N, Kendall J, Troge J, et al. Tumor Evolution Inferred by Single 
Cell Sequencing. 
Nature. 2011;472(7341):90-94. doi:10.1038/nature09807.](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4504184/)
In particular we will use single-cell data for polygenomic breast tumor T10 case available from SRA.
Description of samples for T10 could be found in
[Supplementary Table 1 | Summary of 100 Single Cells in the Polygenomic Tumor 
T10](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4504184/bin/NIHMS706545-supplement-Supplement_Table_1.xls)

Here we will execute *SCclust* package on input prepared by *sgains* pipeline [`varbin` step](https://github.com/KrasnitzLab/sgains/blob/master/docs/tutorial-navin2011.md#varbin-step).
Alternatively, the reader can go through the data pre-processing steps following [*sgains* T10 tutorial](https://github.com/KrasnitzLab/sgains/blob/master/docs/tutorial-navin2011.md).

For the purposes of this tutorial we recomend that you download already prepared `varbin` data from 
[example data](https://github.com/KrasnitzLab/SCclust/releases/download/v1.0.0RC3/navin_t10_varbin_data.tar.gz).
Apart from `varbin` T10 data you will need the binning scheme used in the analysis, which could be found [here](https://github.com/KrasnitzLab/SCclust/releases/download/v1.0.0RC3/hg19_R50_B20k_bins_boundaries.txt.gz).
Finally, we will need `cytoBand.txt`, the cytoband annotation file for the HG19 version of the human genome, which can be downloaded
from the UCSC Genome Browser.

## Collect the Neccessary Data

We first create a directory where the data used in this tutorial will be stored:

```bash
mkdir T10data
cd T10data
```

then download and extract T10 `varbin` data:

```bash
wget -c \
  https://github.com/KrasnitzLab/SCclust/releases/download/v1.0.0RC3/navin_t10_varbin_data.tar.gz
tar zxvf navin_t10_varbin_data.tar.gz
rm navin_t10_varbin_data.tar.gz
```

We also download and extract the binning scheme used in preparation of `varbin` data:

```bash
wget -c \
  https://github.com/KrasnitzLab/SCclust/releases/download/v1.0.0RC3/hg19_R50_B20k_bins_boundaries.txt.gz
gunzip hg19_R50_B20k_bins_boundaries.txt.gz
```

And finally we download the `cytoBand.txt` for Human reference genome *hg19*:

```bash
wget -c \
  http://hgdownload.cse.ucsc.edu/goldenPath/hg19/database/cytoBand.txt.gz
gunzip cytoBand.txt.gz
```

The data directory should have following structure:

```bash
.
|-- T10data
    |-- cytoBand.txt
    |-- hg19_R50_B20k_bins_boundaries.txt
    |-- varbin
        |-- SRR052047.varbin.20k.txt
        |-- SRR052148.varbin.20k.txt
        |-- SRR053437.varbin.20k.txt
        ...
```

## Explore the Downloaded Data

Next, we attach *SCclust* to the R session:

```{r}
library("SCclust")
```

```{r}
library(futile.logger)
flog.threshold(ERROR)
```

### Binning scheme

\todo{Describe the data.}
The binning scheme is a table describing a partition of the genome into bins to sort the sequence reads into. The bin boundaries 
are defined such that each bin contains an approximately equal number of uniquely mapping reads. Also tabulated is the GC content of 
each bin.

```{r, results = "asis"}
gc_df <- read.csv("T10data/hg19_R50_B20k_bins_boundaries.txt", header = T, sep='\t')
gc_df$chrom.numeric <- chrom_numeric(gc_df$bin.chrom)
pander::pandoc.table(head(gc_df))
```

We are using a binning scheme with 20000 bins:

```{r, results = "asis"}
dim(gc_df)
```



### Cytobands and Centromeres for HG19

\todo{Describe the data.}

```{r, results = "asis"}
cytobands <- read.csv("T10data/cytoBand.txt", header = F, sep='\t')
knitr::kable(head(cytobands))
```

The main reason we need `cytoBand.txt` is to get the location of centromeres. Centromeric regions of the genome often 
contain repetitive sequence, leading to mapping artefacts and distorted read counts. For this reason, we opt to mask them 
prior to copy-number profile segmentation.

To identify centromeric regions to be masked we use `calc_centroareas` function:

```{r, results = "asis"}
centroareas <- calc_centroareas(cytobands)
knitr::kable(head(centroareas))
```


The locations of centromeric regions are now tabulated in `centroareas`.

### Varbin Samples Data

\todo{Describe the data.}
Each 'varbin' file is a comma-separated table with each row representing a bin and with columns for etc.

```{r, results = "asis"}
sample_df <- read.csv("T10data/varbin/SRR052047.varbin.20k.txt", header=T, sep='\t')
knitr::kable(head(sample_df))
```

```{r, results = "asis"}
sample_df <- read.csv("T10data/varbin/SRR052148.varbin.20k.txt", header=T, sep='\t')
knitr::kable(head(sample_df))
```

# Segmentation of Varbin Data

## Prepare list of bins that are inside or intersect with centromeres regions

Next, we use the `calc_regions2bins` function to determine which bins overlap with regions tabulated in `centroareas`:

```{r, results = "asis"}
centrobins <- calc_regions2bins(gc_df, centroareas)
length(centrobins)
```

## Exclude centromeric bins from the binning scheme

After excluding centromeric bins from the binning scheme, the new binning scheme has fewer bins:

```{r, results = "asis"}
gc_df <- gc_df[-centrobins, ]
dim(gc_df)
```

## Collect Varbin files for all samples

With the help of `varbin_input_files` we create a vector of character strings, each representing a path to a `varbin` data file 
in `T10data/varbin` directory:

```{r, results = "asis"}
varbin_files <- varbin_input_files("T10data/varbin", "*.varbin.20k.txt")
knitr::kable(head(varbin_files))
```

For the purpose of this tutorial we will use a subset of the first 10 samples out of a 100 totalfound by `varbin_input_files` function:

```{r}
varbin_files <- varbin_files[seq(10),]
dim(varbin_files)
```

## Segment varbin files

\todo{Explain segmentation}
Next, we approximate the copy number ratio as a function of the bin number by a piecewise-constant function. This process is called 
segmentation. The segmentation algorithm we use is Circular Binary Segmentation (CBS), as implemented in the R package `DNAcopy`, but 
modified for a more consistent elimination of very short segments.

```{r}
res <- segment_varbin_files(varbin_files, gc_df, centrobins)
```

The `segment_varbin_files` function returns the segmented copy number ratio along with the input ratios for all the samples

```{r, results = "asis"}
knitr::kable(head(res$seg))
```

```{r, results = "asis"}
knitr::kable(head(res$ratio))
```

## Construct file names for the segmented output and store segmentation and ratio results.

```{r}
filenames <- case_filenames("T10data/results", "NavinT10")
```

```{r}
save_table(filenames$seg, res$seg)
save_table(filenames$ratio, res$ratio)
```



```{r}
cells <- uber_cells(res$seg)$cells
save_table(filenames$cells, data.frame(cell=cells))
```


```{r}
dir("T10data/results")
```


# Construct features and feature matrix

\todo{Where do we remove shredded cells?}
\todo{Explain how we calculate features}
At this point, we convert the set of segmented copy number profiles into a feature matrix. This process includes a number of steps. 
First, since single-cell copy number must be integer, we round the segmented values to the nearest integer. Some of the neighboring 
segments may merge as a result. Next, we replace each profile by a set of change points, i.e., discontinuities in the integer segmented
value. Each change point has two values associated with it: position (bin number) and the sign of change going in the direction of
increasing bin number. The positive and negative change points are handled separately.  Further, we turn change points into short 
intervals centered at the change point positions, with the interval length is an integer number of bin sdetermined by the `smear` 
parameter. For each sign of the change points, the features are a minimal set of points such that at least one of them is contained 
in each of the short intervals centered at the change points. The feature matrix  is then a binary matrix with cells as columns 
and features as rows, indicating, for each cell and feature, the presence of a short change-point centered interval containing the 
feature. The results are stored in a list called `pins`, with two items: `pins` is a tabulation of the feature locations and signs and
`pinmat` is the feature matrix.
```{r}
pins <- calc_pinmat(gc_df, res$seg, dropareas=centroareas)
pinmat_df <- pins$pinmat
pins_df <- pins$pins
save_table(filenames$featuremat, pinmat_df)
save_table(filenames$features, pins_df)
```

```{r}
dir("T10data/results")
```


# Dissimilarity matrix and significance of dissimilarities

In the next step, we use the feature matrix to compute dissimilarities among cells. These are defined, for each pair of cells,
as (one-sided) Fisher test p-values for the corresponding two columns of the feature matrix. To analyze the significance of 
dissimilarities, we will need to compare their observed distribution to a sampling from a null model. For the latter, we perform `nsim` 
permutations of the feature set, preserving the column and, approximately, the row sums and recomputing the dissimilarity matrix each 
time. Each permutation consists of `nsweep` sweeps. A sweep consists of a Metroplolis-Hastings step for every row and a swapping move 
for pairs of columns, such that every column is involved. Positive and negative feature submatrices are permuted separately. The entire 
procedure is implemented as `sim_fisher_wrapper` function, which returns a list, with the vectors of the observed dissimilarities and 
those sampled from the null distribution as items.
```{r}
fisher <- sim_fisher_wrapper(
      pinmat_df, pins_df, njobs=30, nsim=150, nsweep=10)
true_pv <- fisher$true
sim_pv <- fisher$sim
```
These distributuions can be saved if so desired.
```{r}
save_mat(filenames$true_pv, true_pv)
save_mat(filenames$sim_pv, sim_pv)
```
Next, we use function `fisher_fdr` to determine which of the observed dissimilarities are outliers on the left in the null distribution, 
i.e., much smaller than expected. The value is a matrix of false discovery rates (FDR) for every pair of cells. We also arrange the 
observed dissimilarities in a distance matrix.
```{r}
# devtools::load_all()
# flog.threshold(DEBUG)
mfdr <- fisher_fdr(true_pv, sim_pv, cells)
mdist <- fisher_dist(true_pv, cells)
```



# Hierarchical clustering

```{r}
hc <- hclust_tree(pinmat_df, mfdr, mdist)
tree_df <- tree_py(mdist, method='average')
```


```{r}
save_table(filenames$tree, tree_df)
```


# Finding clones and subclones

```{r}
hc <- find_clones(hc)
subclones <- find_subclones(hc, pinmat_df, pins_df, nsim=nsim)
```

```{r}
save_table(filenames$clone, subclones)
```
